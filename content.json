{"meta":{"title":"流浪的少年","subtitle":null,"description":null,"author":"zhengyang","url":"http://yoursite.com"},"pages":[{"title":"","date":"2017-08-05T13:19:16.000Z","updated":"2017-08-20T10:54:23.706Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":""}],"posts":[{"title":"处理器相关知识概要","slug":"处理器相关知识概要","date":"2017-09-04T14:05:13.000Z","updated":"2017-09-04T14:31:55.198Z","comments":true,"path":"2017/09/04/处理器相关知识概要/","link":"","permalink":"http://yoursite.com/2017/09/04/处理器相关知识概要/","excerpt":"","text":"《计算机组成与设计——软件/硬件接口》 第四章 处理器性能评估标准 指令数 CPI（执行每条指令需要的周期数） 时钟周期的长度 流水线相关单周期还是流水线设计 单周期 一个时钟周期执行一条指令指令的实现机制，时钟周期对所有指令等长，时钟周期由执行时间最长的那条指令决定，使得指令执行的性能不是太好 流水线设计 MIPS的指令集是针对流水线做了优化的 所有的MIPS指令长度都是等长的，简化了取指和译码的过程 MIPS中指令的格式比较少而且指令中源寄存器字段的位置都是相同的 MIPS中的存储器操作数仅出现在存取指令中 所有的操作数在存储器中对齐，实现一次访存就完成请求数据的传输 流水线冒险 结构冒险：处理器硬件不能实现指令的流水线执行，导致指令无法在固定的时钟周期内执行。 数据冒险：无法提供指令执行所需数据导致指令不能在预定的时钟周期内执行的情况。 主要原因：一条指令依赖于更早一条还在流水线中的指令造成的。 解决方法：是采取 前推 或者 旁路 的方法。 控制冒险：也称为 分支冒险，取到的指令并不是所需要的而导致指令不能在预定的时钟周期内执行。 解决方法： 流水线阻塞 分支预测：预测分支结果并立即执行，而不是等分支结果确定以后才开始执行。 CPU执行指令的流水线 取指：从指令存储器读取指令 译码：指令译码的同时读取寄存器（MIPS允许指令译码和读取寄存器） 执行：执行操作或者计算地址 数据存储器访问：从数据存储器中读取操作数 写回：将结果写回寄存器 指令集并行增加流水线并行度的方法 增加流水线的深度以及重叠更多的指令。 复制计算机内部部件的数量，使得每个流水线可以启动多条指令（即多发射）。 静态多发射：编译器静态编译进行的。 动态多发射：指令在执行时由处理器部件动态进行的。 静态多发射处理器 发射包：在一个时钟周期内发射的多条指令的集合。 超长指令字：一类可以同时启动多个操作的指令集，其中操作在单个指令中互相独立，并且一般都有独立的操作码段。 寄存器重命名：在循环展开的时候，编译器引入几个临时的寄存器。目的是消除指令之间一些虚假的数据依赖，这些虚假的数据依赖可能导致潜在的冒险或者妨碍编译器灵活的调度。 动态多发射处理器（超标量） 在最简单的超标量处理器中，指令顺序发射，每个周期处理器决定是发射0条、1条还是多条指令，要达到好的性能依然依赖编译器的调度以达到错过数据依赖的目的。但是不管代码是否经过调度，都是由硬件来保证执行的正确性。而且编译器得到的代码始终正确执行，跟处理器的流水线结构和指令发射速率无关。 动态流水线调度：对指令进行重排序以避免阻塞的硬件支持。 提交单元：位于动态流水线和乱序流水线中的一个单元，用以决定何时将结果送至程序员可见的寄存器和存储器。 功能单元：用来保存操作数和寄存器。 重排序缓冲区（提交单元中的缓冲区，reorder buffer）：动态调度处理器中用来保存执行结果的缓冲区，等到安全时才将其中的结果写回寄存器或存储器。","categories":[{"name":"计算机体系结构","slug":"计算机体系结构","permalink":"http://yoursite.com/categories/计算机体系结构/"}],"tags":[{"name":"处理器","slug":"处理器","permalink":"http://yoursite.com/tags/处理器/"}]},{"title":"Linux常用命令","slug":"Linux常用命令","date":"2017-08-23T07:10:23.000Z","updated":"2017-08-23T07:22:58.500Z","comments":true,"path":"2017/08/23/Linux常用命令/","link":"","permalink":"http://yoursite.com/2017/08/23/Linux常用命令/","excerpt":"","text":"注：图片转载自 王爵的技术小黑屋——写代码怎能不会这些Linux命令？","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"}]},{"title":"死锁","slug":"死锁","date":"2017-08-20T08:42:51.000Z","updated":"2017-08-20T08:47:28.644Z","comments":true,"path":"2017/08/20/死锁/","link":"","permalink":"http://yoursite.com/2017/08/20/死锁/","excerpt":"","text":"资源死锁主要是跟资源相关，一般情况下，资源可以是硬件设备（比如磁带、打印机）或者是一组信息（如数据库中一个加锁的记录）。资源分为可抢占和不可抢占： 可抢占式资源：可以从拥有它的进程中抢占而不会产生任何副作用，比如存储器。 不可抢占式资源：指的是在不引起相关计算失败的情况下，无法把它从占有它的进程处抢占过来，比如CD刻录机正在被一个进程抢占的时候，其他的进程如果抢占CD刻录机会导致原始的刻录失败。 资源的使用情况为： 请求资源 使用资源 释放资源 进程请求和使用资源就会产生一定的问题，比如2个进程A和B，A占有a资源，B占有b资源，如果A请求b资源的同时B也同时请求a资源，且双方都没有释放原有的资源，此时就会产生死锁问题。 死锁概述 如果一个进程集合中的每个进程都在等待只能由该进程集合中的其他进程才能引发的事件，那么此进程集合就是 死锁 的。 资源死锁发生的4个必要条件： 互斥条件。每个资源要么已经分配给一个进程，要么就是可用的。 占有和等待条件。已经得到某个资源的进程可以再请求其他新的资源。 不可抢占条件。已经分配给一个进程的资源不能强制性的被抢占，它只能被占有它的进程显示的释放。 环路等待条件。死锁发生时，系统中一定有两个或者两个以上的进程组成的一条环路，该环路中有的每个进程都在等待着下一个进程所占有的资源。 处理死锁的策略： 忽略该问题。也许如果你忽略它，它也会忽略你。【不闻不顾】 检测死锁并恢复。让死锁发生，检测他们是否发生，一旦发生死锁，才去行动解决问题。【亡羊补牢】 仔细对资源进行分配，动态得到避免死锁。【未雨绸缪】 通过破坏引起死锁的四个必要条件之一，防止死锁的发生。【追本溯源】 处理死锁的几种思路鸵鸟算法 鸵鸟算法：把头埋进沙子中，假装根本没有问题发生。 这里主要讲的是死锁问题在某些情况下是否值得解决？数学家认为程序讲究的是完备性，不管效率之类的问题，必须解决。而工程师首先需要评估死锁发生的频率、系统因各种原因崩溃的发生次数以及死锁的严重性，如果死锁5年发生一次，而其他的硬件故障等导致系统每月崩溃一次，那么工程师是不会以性能损失和可用性的代价去防止死锁。 死锁检测和死锁恢复（1）死锁检测 每种类型一个资源的死锁检测 主要涉及到有向图的深度优先搜索。 每种类型多个资源的死锁检测 （2）死锁恢复 假设检测算法已经检测到系统中产生了死锁问题，接下来就是考虑如何恢复系统的正常运行了。 利用抢占恢复在不通知原进程的情况下，将某一资源从一个进程强行取走给另一个进程使用，接着又送回，这种做法是否可行主要取决于该资源本身的特性。用这种方法恢复通常比较困难或者说不太可能。若选择挂起一个进程，则在很大程度上取决于一个进程拥有比较容易回收的资源。 利用回滚恢复 周期性的备份进程作为检查点（包含存储映像、资源状态、资源分配给了哪些进程），而且新的检查点不会覆盖原有的检查点，一旦检查到进程出现了死锁现象，将进程复位到死锁出现之前的状态。 杀死进程恢复 通过杀死死锁环上的进程，直接破坏死锁环路；杀死死锁环路以外的进程作为牺牲品，从而释放资源；最好杀死可以从头开始运行而不会带来副作用的进程。 死锁预防 死锁避免从本质上是不可能的，因为它需要获知未来的请求，而这些请求是不可知的。 通过破坏死锁环路，我们可以避免死锁： 破坏互斥条件 资源不被一个进程独占，那么死锁是不会发生的。 破坏占有和等待条件 当一个进程获得所需要的全部资源后才开始运行，这样不会产生死锁，但是会造成运行效率低下。 破坏不可抢占条件 破坏环路等待条件 请求其他资源之前释放掉现在占有的资源；对所有资源统一编号，以保证资源请求的有序性，从而不会产生死锁。 其他问题两阶段加锁第一阶段对需要的资源进行加锁，第二阶段完成更新后释放锁。主要在于第一阶段，如果进程请求的部分资源已经被其他进程加锁，那么需要释放现在已经加锁的资源，然后重新开始第一阶段。 通信死锁死锁并不局限于资源死锁，比如通信中客户端和服务器端由请求信号丢失，相互等待对方的信号产生死锁。 活锁 没有出现死锁现象（因为无进程阻塞），但是从现象上看好像死锁发生了，这就是活锁。 指事物1可以使用资源，但它让其他事物先使用资源；事物2可以使用资源，但它也让其他事物先使用资源，于是两者一直谦让，都无法使用资源。 避免活锁的简单方法是采用先来先服务的策略。当多个事务请求封锁同一数据对象时，封锁子系统按请求封锁的先后次序对事务排队，数据对象上的锁一旦释放就批准申请队列中第一个事务获得锁。 饥饿一个进程由于优先级等情况一直被延迟执行而导致“饥饿而死”（无限制地推后，尽管它没有被阻塞）。 饥饿可以通过先来先服务资源分配策略来避免，在此情形下，等待最久的进程会是下一个被调度的进程，随着时间的推移，所有进程都会变成最“老”的，因为，最终能够获得资源而完成。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"http://yoursite.com/categories/操作系统/"}],"tags":[{"name":"OS","slug":"OS","permalink":"http://yoursite.com/tags/OS/"}]},{"title":"Hexo使用","slug":"hexo使用","date":"2017-08-05T14:27:41.000Z","updated":"2017-08-20T09:18:56.931Z","comments":true,"path":"2017/08/05/hexo使用/","link":"","permalink":"http://yoursite.com/2017/08/05/hexo使用/","excerpt":"","text":"今天摆弄了一天Hexo的使用方法，由于自己对建站不是很熟悉，从解析域名到托管网站，以及修改主题模板，都耗费了不少的时间，不过欣喜的是现在网站总算有点模样了。 Hexo安装下载Node.js我是在Windows下安装的Node.js，安装好以后再cmd命令下可以显示如下的效果12345$ C:\\Users\\zy&gt;node -vv8.2.1$ C:\\Users\\zy&gt;npm -v5.3.0 安装Hexo采用npm包管理软件安装hexo会非常慢，搜索了下，建议从淘宝的镜像站点安装，输入如下的命令1$ npm install -g cnpm --registry=https://registry.npm.taobao.org 以后，凡是涉及到npm安装软件，都采用cnpm命令安装，可以极快的提高软件下载安装速度。接下来就是安装hexo了1234567891011121314151617$ cnpm install hexo-cli -g $ cnpm install hexo --save$ hexo -vhexo-cli: 1.0.3os: Windows_NT 10.0.14393 win32 x64http_parser: 2.7.0node: 8.2.1v8: 5.8.283.41uv: 1.13.1zlib: 1.2.11ares: 1.10.1-DEVmodules: 57openssl: 1.0.2licu: 59.1unicode: 9.0cldr: 31.0.1tz: 2017b 这样就算是完成了hexo的安装。","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"}]},{"title":"计算机存储结构的区别","slug":"计算机体系结构的区别","date":"2017-08-05T12:26:24.000Z","updated":"2017-08-05T12:41:47.930Z","comments":true,"path":"2017/08/05/计算机体系结构的区别/","link":"","permalink":"http://yoursite.com/2017/08/05/计算机体系结构的区别/","excerpt":"","text":"哈佛结构哈佛结构是一种将程序指令存储和数据存储分开的存储器结构。中央处理器首先到程序指令存储器中读取程序指令内容，解码后得到数据地址，再到相应的数据存储器中读取数据，并进行下一步的操作（通常是执行）。程序指令存储和数据存储分开，可以使指令和数据有不同的数据宽度，如Microchip公司的PIC16芯片的程序指令是14位宽度，而数据是8位宽度。目前使用哈佛结构的中央处理器和微控制器有很多，除了上面提到的Microchip公司的PIC系列芯片，还有摩托罗拉公司的MC68系列、Zilog公司的Z8系列、ATMEL公司的AVR系列和安谋公司的ARM9、ARM10和ARM11，51单片机也属于哈佛结构 冯·诺伊曼结构冯·诺伊曼结构也称普林斯顿结构，是一种将程序指令存储器和数据存储器合并在一起的存储器结构。程序指令存储地址和数据存储地址指向同一个存储器的不同物理位置，因此程序指令和数据的宽度相同，如英特尔公司的8086中央处理器的程序指令和数据都是16位宽。 目前使用冯·诺伊曼结构的中央处理器和微控制器有很多。除了上面提到的英特尔公司的8086，英特尔公司的其他中央处理器、安谋公司的ARM7、MIPS公司的MIPS处理器也采用了冯·诺伊曼结构。 哈佛结构和冯.诺依曼结构都是一种存储器结构。哈佛结构是将指令存储器和数据存储器分开的一种存储器结构；而冯.诺依曼结构将指令存储器和数据存储器合在一起的存储器结构。 嵌入式系统的存储结构MCS-51单片机有着嵌入式处理器经典的体系结构，这种体系结构在当前嵌入式处理器的高端ARM系列上仍然在延续，这就是哈佛结构。相对于大名鼎鼎的冯·诺依曼结构，哈佛结构的知名度显然逊色许多，但在嵌入式应用领域，哈佛结构却拥有着绝对的优势。哈佛结构与冯·诺依曼结构的最大区别在于冯·诺依曼结构的计算机采用代码与数据的统一编址，而哈佛结构是独立编址的，代码空间与数据空间完全分开。 在通用计算机系统中，应用软件的多样性使得计算机要不断地变化所执行的代码的内容，并且频繁地对数据与代码占有的存储器进行重新分配，这种情况下，冯·诺依曼结构占有绝对优势，因为统一编址可以最大限度地利用资源，而哈佛结构的计算机若应用于这种情形下则会对存储器资源产生理论上最大可达50%的浪费，这显然是不合理的。 但是在嵌入式应用中，系统要执行的任务相对单一，程序一般是固化在硬件里。当然这时使用冯·诺依曼结构也完全可以，代码区和数据区在编译时一次性分配好了而已，但是其灵活性得不到体现，所以现在大量的单片机也还在沿用冯·诺依曼结构，如TI的MSP430系列、Freescale的HCS08系列等。 那是为什么说哈佛结构有优势呢？嵌入式计算机在工作时与通用计算机有着一些区别：嵌入式计算机在工作期间的绝大部分时间是无人值守的，而通用计算机工作期间一般是有人操作的；嵌入式计算机的故障可能会导致灾难性的后果，而通用计算机一般就是死死机，重新启动即可。这两点决定了对嵌入式计算机的一个基本要求：可靠性。 使用冯·诺依曼结构的计算机，程序空间不封闭，期程序空间的数据在运行期理论上可以被修改，此外程序一旦跑飞也有可能运行到数据区。虽然都是一些不常见的特殊情况下，但是看看哈佛结构德计算机在这些情况下是怎样的：基于哈佛结构的处理器入MCS-51，不需要可以对代码段进行写操作的指令，所以不会有代码区被改写的问题；程序只能在封闭的代码区中运行，不可能跑到数据区，这也是跑飞的几率减少并且跑飞后的行为有规律（数据区的数据是不断变化的而代码区是不变的）。 所以，相对于冯·诺依曼结构，哈佛结构更加适合于那些程序固化、任务相对简单的控制系统。 总结冯.诺依曼结构：程序只是一种（特殊）的数据，它可以像数据一样被处理，因此可以和数据一起被存储在同一个存储器中——这就是著名的冯.诺依曼原理。注意:数据总线和地址总线共用。 哈佛结构:一种并行体系结构，它的主要特点是将程序和数据存储在不同的存储空间中，即程序存储器和数据存储器是两个独立的存储器，每个存储器独立编址、独立访问。与两个存储器相对应的是系统的4条总线：程序的数据总线与地址总线，数据的数据总线与地址总线。这种分离的程序总线和数据总线允许在一个机器周期内同时获得指令字（来自程序存储器）和操作数（来自数据存储器），从而提高了执行速度，使数据的吞吐率提高了1倍。又由于程序和数据存储器在两个分开的物理空间中，因此取指和执行能完全重叠。CPU首先到程序指令存储器中读取程序指令内解码后得到数据地址，再到相应的数据存储器中读取数据，并进行下一步的操作（通常是执行）。","categories":[{"name":"计算机体系结构","slug":"计算机体系结构","permalink":"http://yoursite.com/categories/计算机体系结构/"}],"tags":[{"name":"体系结构","slug":"体系结构","permalink":"http://yoursite.com/tags/体系结构/"}]}]}